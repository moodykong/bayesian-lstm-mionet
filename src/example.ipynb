{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================\n",
      "Default dataset parameters:\n",
      "ode_system = pendulum\n",
      "t_max = 20\n",
      "step_size = 0.01\n",
      "n_sample = 10\n",
      "x_init_pts = [[-3.14159265  3.14159265]\n",
      " [-8.          8.        ]]\n",
      "ctr_func = gaussian\n",
      "datafile_path = data/pendulum_ctr_gaussian_N_10_T20.npy\n",
      "\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from argparse import ArgumentParser\n",
    "import os, sys\n",
    "from importlib import reload\n",
    "from config import data_config\n",
    "from utils.args_parser import add_data_args\n",
    "\n",
    "# Reload arg_parser because Jupyter notebook does not reload it automatically\n",
    "reload(data_config)\n",
    "\n",
    "# Add arguments to parser\n",
    "parser = ArgumentParser()\n",
    "parser = add_data_args(parser)\n",
    "\n",
    "# Print default dataset parameters\n",
    "args = parser.parse_args([])\n",
    "print(\"\\n=====================\")\n",
    "print(\"Default dataset parameters:\")\n",
    "for arg in vars(args):\n",
    "    print(arg, '=', getattr(args, arg))\n",
    "print(\"\\n=====================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====================\n",
      "Running database_generator.py with arguments:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/PENDULUM/src/config/data_config.py:35: RuntimeWarning: invalid value encountered in subtract\n",
      "  u - b * omega - 0.5 * m * l * g * np.sin(theta)\n",
      "/PENDULUM/src/config/data_config.py:35: RuntimeWarning: invalid value encountered in sin\n",
      "  u - b * omega - 0.5 * m * l * g * np.sin(theta)\n",
      "Generating 50 data ...: 100%|██████████| 50/50 [00:08<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved in data/pendulum_ctr_grf_N_50_T10.npy .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run database_generator.py with arguments\n",
    "print(\"\\n=====================\")\n",
    "print(\"Running database_generator.py with arguments:\")\n",
    "%run database_generator.py --n_sample 50 --ctr_func \"gaussian\" --t_max 10 --datafile_path \"data/pendulum_ctr_grf_N_50_T10.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using all available 1 GPUs.\n",
      "Shapes for LSTM-MIONet training input=(18000, 999, 1), x_n=(18000, 1), x_next=(18000, 1)\n",
      "Shapes for LSTM-MIONet training input=(2000, 999, 1), x_n=(2000, 1), x_next=(2000, 1)\n",
      "Data memory size: 68 MB\n",
      "Data memory size: 7 MB\n",
      "LSTM_MIONet_Static(\n",
      "  (layernorm): LayerNorm((150,), eps=1e-05, elementwise_affine=True)\n",
      "  (layernorm_x_n): LayerNorm((150,), eps=1e-05, elementwise_affine=True)\n",
      "  (layernorm_delta_t): LayerNorm((150,), eps=1e-05, elementwise_affine=True)\n",
      "  (lstm): LSTM(150, 10, num_layers=2, batch_first=True)\n",
      "  (cell_mlp): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=150, bias=True)\n",
      "  )\n",
      "  (input_mlp): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=150, bias=True)\n",
      "  )\n",
      "  (delta_t_mlp): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=150, bias=True)\n",
      "  )\n",
      "  (x_n_mlp): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=150, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "***** Training with Adam Optimizer for 1000 epochs and using 18000 data samples*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Index is supposed to be an empty tensor or a vector",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/PENDULUM/src/train.py:159\u001b[0m\n\u001b[1;32m    155\u001b[0m     run(config)\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 159\u001b[0m     main()\n",
      "File \u001b[0;32m/PENDULUM/src/train.py:155\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m os\u001b[39m.\u001b[39mmakedirs(config[\u001b[39m\"\u001b[39m\u001b[39mcheckpoint_path\u001b[39m\u001b[39m\"\u001b[39m], exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    154\u001b[0m \u001b[39m# Run the program\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m run(config)\n",
      "File \u001b[0;32m/PENDULUM/src/train.py:128\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m    124\u001b[0m \u001b[39m###################################\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m# Step 8: train the model\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m###################################\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m execute_train(\n\u001b[1;32m    129\u001b[0m     config\u001b[39m=\u001b[39;49mconfig, model\u001b[39m=\u001b[39;49mmodel, dataset\u001b[39m=\u001b[39;49mtrain_data_torch, device\u001b[39m=\u001b[39;49mtorch_utils\u001b[39m.\u001b[39;49mdevice\n\u001b[1;32m    130\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39m###################################\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m# Step 9: test the model\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m###################################\u001b[39;00m\n\u001b[1;32m    136\u001b[0m execute_test(config\u001b[39m=\u001b[39mconfig, model\u001b[39m=\u001b[39mmodel, dataset\u001b[39m=\u001b[39mtest_data_torch)\n",
      "File \u001b[0;32m/PENDULUM/src/optim/supervisor.py:106\u001b[0m, in \u001b[0;36mexecute_train\u001b[0;34m(config, model, dataset, device)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mfor\u001b[39;00m x_batch, y_batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m    103\u001b[0m     \u001b[39m## batch training\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[39mwith\u001b[39;00m autocast():\n\u001b[1;32m    105\u001b[0m         \u001b[39m# step a: forward pass\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m         y_pred \u001b[39m=\u001b[39m model(x_batch)\n\u001b[1;32m    108\u001b[0m         \u001b[39m# step b: compute loss\u001b[39;00m\n\u001b[1;32m    109\u001b[0m         loss \u001b[39m=\u001b[39m loss_fn(y_pred, y_batch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:169\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     kwargs \u001b[39m=\u001b[39m ({},)\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule(\u001b[39m*\u001b[39;49minputs[\u001b[39m0\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    170\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[1;32m    171\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel_apply(replicas, inputs, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/PENDULUM/src/models/architectures.py:85\u001b[0m, in \u001b[0;36mLSTM_MIONet_Static.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m mask \u001b[39m=\u001b[39m (x \u001b[39m!=\u001b[39m \u001b[39m0.0\u001b[39m)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mbool)\n\u001b[1;32m     81\u001b[0m mask_len \u001b[39m=\u001b[39m (\n\u001b[1;32m     82\u001b[0m     mask\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mint64)\u001b[39m.\u001b[39mcpu() \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     83\u001b[0m )\n\u001b[1;32m     84\u001b[0m latent_x_packed \u001b[39m=\u001b[39m (\n\u001b[0;32m---> 85\u001b[0m     pack_padded_sequence(\n\u001b[1;32m     86\u001b[0m         latent_x, mask_len, batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, enforce_sorted\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m mask_len \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[39melse\u001b[39;00m latent_x\n\u001b[1;32m     90\u001b[0m )\n\u001b[1;32m     92\u001b[0m output, (h_n, c_n) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(latent_x_packed)\n\u001b[1;32m     93\u001b[0m memory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell_mlp(c_n[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/utils/rnn.py:260\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    258\u001b[0m     sorted_indices \u001b[39m=\u001b[39m sorted_indices\u001b[39m.\u001b[39mto(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    259\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m batch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 260\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mindex_select(batch_dim, sorted_indices)\n\u001b[1;32m    262\u001b[0m data, batch_sizes \u001b[39m=\u001b[39m \\\n\u001b[1;32m    263\u001b[0m     _VF\u001b[39m.\u001b[39m_pack_padded_sequence(\u001b[39minput\u001b[39m, lengths, batch_first)\n\u001b[1;32m    264\u001b[0m \u001b[39mreturn\u001b[39;00m _packed_sequence_init(data, batch_sizes, sorted_indices, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Index is supposed to be an empty tensor or a vector"
     ]
    }
   ],
   "source": [
    "%run train.py --datafile_path \"data/pendulum_ctr_grf_N_5000_T10.npy\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
